\chapter{Reducing special ILPs to Shortest Path}
\section{Problem statement}
In their book \textit{Algebraic statistics for computational biology} \cite{algebraic_statistics}, the authors briefly mention an algorithm to solve integer linear programs by constructing a certain graph and solving the shortest path problem between two specifically chosen vertices. The resulting path will dictate the solution vector, and the length of that path will represent the value of that solution. Initially, this approach was restricted to matrices whose columns all sum up to the same number. In this chapter, we aim to revisit and rigorously explain this result. Furthermore, to enhance the practical feasibility of this algorithm, we will present some ideas to accelerate its execution.

\section{Solving Shortest Path using Dijkstra's Algorithm}
Before delving into the translation of Integer Linear Programs (ILPs) to a shortest path problem, let's revisit the fundamental concept of finding the shortest path in a graph. Dijkstra's algorithm stands as a cornerstone in graph theory, offering a systematic approach to determine the shortest path between nodes in a weighted graph \cite{introduction_to_algorithms}. It works by iteratively selecting the vertex with the shortest distance from the source and relaxing its outgoing edges. Here's how it works:

\subsection{Algorithm}
Given a weighted graph $G = (V, E)$ with vertices $V$ and edges $E$, and two specified vertices $s$ (source) and $t$ (target), we aim to find the shortest path from $s$ to $t$. Let $w(u, v)$ denote the weight of the edge from vertex $u$ to vertex $v$.

\begin{enumerate}
    \item Initialize a priority queue $Q$ and an array $dist$ to keep track of the shortest distance from the source vertex $s$ to every other vertex in the graph. Initially, set $dist[v] = \infty$ for all vertices $v$, except for $dist[s] = 0$.
    \item Enqueue the source vertex $s$ into the priority queue $Q$ with priority $0$.
    \item While $Q$ is not empty:
    \begin{enumerate}
        \item Dequeue a vertex $u$ with the minimum priority from $Q$.
        \item For each neighbor $v$ of $u$:
        \begin{enumerate}
            \item Calculate the potential new shortest distance to $v$ as $new\_dist = dist[u] + w(u, v)$.
            \item If $new\_dist < dist[v]$, update $dist[v]$ to $new\_dist$ and enqueue $v$ into $Q$ with priority $new\_dist$.
        \end{enumerate}
    \end{enumerate}
    \item Once the target vertex $t$ is dequeued from $Q$, the shortest path has been found, and the shortest distance to $t$ is $dist[t]$.
\end{enumerate}

\subsection{Pseudocode}
Here's the pseudocode for Dijkstra's algorithm:

\begin{verbatim}
function Dijkstra_Shortest_Path(G, s, t):
    dist = array of size |V| with all elements set to infinity
    dist[s] = 0
    Q = priority queue initialized with (s, 0)
    
    while Q is not empty:
        u, priority = Q.dequeue_min()
        if u == t:
            return dist[t]  // Shortest distance found
        for each neighbor v of u:
            new_dist = dist[u] + w(u, v)
            if new_dist < dist[v]:
                dist[v] = new_dist
                Q.enqueue(v, new_dist)
    return "No path found"
\end{verbatim}

\subsection{Runtime Analysis}
The runtime complexity of Dijkstra's algorithm is $O((|V| + |E|) \log |V|)$ using a binary heap priority queue implementation. This makes it efficient for finding the shortest path in large, weighted graphs.


\section{Reduction}
\subsection{Definitions and preparation}
As mentioned above, we will exclusively be handling matricies who's columns all sum up to the same number. As this is a mouth full to say (and write), let's define an abbrviation:

\begin{definition}
    Let $\mathbb{K}$ be a field. Let $S_{\alpha}(\mathbb{K}^{m \times n})$ be the set of matricies of size $m \times n$, who's column all sum up to $\alpha \in \mathbb{K}$, namely:
    $$S_{\alpha}(\mathbb{K}^{m \times n}) := \{A \in \mathbb{K}^{m \times n}\mid \forall j \in [n]\colon \sum_{i=1}^{m} A_{ij} = \alpha\}$$
    We will call these matricies \textbf{CCS matricies}, for \textbf{C}onstant \textbf{C}olumn \textbf{S}um.
\end{definition}

At the core of ILPs lies always a system of linear equation $A \vec x = \vec b$. It is crucial to understand that if $A$ is a CCS matrix, all solutions $\vec x$ have certain properties, as described in the first lemma. This will be the key to constructing the graph, our goal. 

\begin{lemma}
    \label{lemma:ilp_pre1}
    Let $A\in S_\alpha(\N^{m \times n})$, $\alpha > 0$. Let $\vec b \in \N^m$ arbitrary and consider the linear system of equation $A\vec x=\vec b$, where $\vec x \in \N^n$. Then, the following two statements are true

    \begin{enumerate}
        \item[(1)] For all solutions $\vec x \in \N^n$ must hold that its components must always sum up to the same number $k$.
        \item[(2)] There only exist a solution of the components of $b$ sum up to a multiple of $\alpha$. This multiple turnes out to be $k \cdot \alpha$.
    \end{enumerate}
\end{lemma}

\begin{proof}
    Let's assume there exists a solution $\vec x \in \N^n$ of the linear system of equation $A\vec x=\vec b$.
    $$\sum_{i=1}^m b_i = \sum_{i=1}^{m}\sum_{j=1}^{n}A_{ij} x_j = \sum_{j=1}^{n}\underbrace{\sum_{i=1}^{m}A_{ij}}_\alpha x_j = \alpha \cdot \sum_{j=1}^{n}x_j$$
    Because $\alpha$ and $b_i$ are fixed and will not change dependent of $\vec x$ and $\alpha \neq 0$, statement (1) immidiatly follows. Thus we have proven, if there exist a solution $\vec x \in \N^n$, then it must hold that $\sum_{i=1}^{m}b_i = \alpha \cdot k$, which is the contraposition of (2).
\end{proof}


\section{Solving ILPs by Shortest Path}
We want to be able to solve an ILP by using the shortest path framework, so the first task is to construct a directect weighted graph $G = (V, E)$ based on an ILP ($\sprod{w}{x} \stackrel{!}{=} \min$ s.t. $Ax=b$). Again we only look at matricies, in which all columns sum up to the same number $\alpha \in \N^*$. Let $k := \frac{1}{\alpha} \sum_{i=1}^{n}x_i \in \N$. Because of Lemma \ref{lemma:ilp_pre1}, $k$ exists. Now we are ready to set the vertecies:
$$V := \left\{Ax \mid x \in \N^n, \sum_{i=1}^{n} x_i \leq k \right\}$$ 
If $Ax=b$ has solutions, we immidiatly see that $b \in V$, because the components of all solutions add up to exactly $k$. We also note that $\vec 0 = A\vec 0 \in V$. Now we can define the edges:
$$E := \{(v, u) \mid v, u \in V, u = v + A\hat e_i, i \in [n]\}$$
In other words, an edge exists, if underlying vectors only differ by an unit vector.

The resulting graph will be a tree with $\vec 0$ as the root. We will define the weight as follow:
$$w(v, v + A\hat e_i) := \sprod{w}{\hat e_i}$$
The nodes with distance $l$ will be the the nodes $Ax$ where $\sum_{i=1}^{n}x_i = l$. So the tree will have depth $k+1$. So the shortest path between $\vec 0$ and $b$ will be 

$$\min\left\{\sum_{l=1}^{k} \sprod{w}{\hat e^{(l)}} \mid \sum_{l=1}^{k}\hat Ae^{(l)} = b, \hat e^{(l)} \in \{\hat e_{1}, \dots, \hat e_n\}\right\}$$

By using the liniarity of the scalar product and the matrix multiplication and than setting $x := \sum_{l=1}^{k}\hat e^{(l)}$ this is equal to 
$$\min\left\{\sprod{w}{x} \mid x \in \N^n, \sum_{i=1}^{n}x_i = k , Ax=b\right\} \stackrel{\ref{lemma:ilp_pre1}}{=} \min\{\sprod{w}{x} \mid x \in \N^n, Ax=b\}$$
which solves th ILP.\qed

\section{Immediate optimisation ideas}
% Nicht mehrere Pfade frü einen Vektor
% Wenn einträge zu groß werden discarden
% Kinderlose löschen
