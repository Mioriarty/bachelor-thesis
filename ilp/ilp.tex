\chapter{Integer linear programs}
\section{Introduction}

\section{Preliminaries}
[Define a ILP?]

For us, it will be usefull to discuss matricies where all columns sum to the same number $\alpha$. Because we are in the framework of ILPs, we also use natural numbers as entries. So, we are interested in $A \in \N^{m \times n}$ if $\forall i \in [n]\colon \sum_{i=1}^{m}A_{ij} = \alpha$. These matricies have special properties when they are used in linear system of equations, which we will discover in the next lemma.

\begin{lemma}
    \label{lemma:ilp_pre1}
    Let $A\in \N^{m \times n}, A \neq \zeromat$ such that each column of $A$ sums up to the same number $\alpha \in \N$. Let $b \in \N^m$ arbitrary and consider the linear system of equation $Ax=b$, where $x \in \N^n$. Then, the following two statements are true

    \begin{enumerate}
        \item[(1)] For all solutions $x \in \R^n$ must hold that its components must always sum up to the same number $k$.
        \item[(2)] There only exist a solution of the components of $b$ sum up to a multiple of $\alpha$. This multiple turnes out to be $k \cdot \alpha$.
    \end{enumerate}
\end{lemma}

\begin{proof}
    $A \neq \zeromat \Rightarrow \alpha > 0$. Lets assume there exists a solution $x \in \R^n$ of the linear system of equation $Ax=b$.
    $$\sum_{i=1}^m b_i = \sum_{i=1}^{m}\sum_{j=1}^{n}A_{ij} x_j = \sum_{j=1}^{n}\underbrace{\sum_{i=1}^{m}A_{ij}}_\alpha x_j = \alpha \cdot \sum_{j=1}^{n}x_j$$
    Because $\alpha$ and $b_i$ are fixed and will not change dependent of $x$ and $\alpha \neq 0$, statement (1) immidiatly follows. Thus we have proven, if there exist a solution $x \in \N^n$, then it must hold that $\sum_{i=1}^{m}b_i = \alpha \cdot k$ which is the contraposition of (2).
\end{proof}
Reviewing the last lemma, one might hope that we can convert any system of lineare equation $Ax = b$ in another $A'x = b'$ such that in $A'$ all columns sum up to the same number and $x$ is a solution to the first if and only if it is a solution to the second. It is easy to see, that this is sadly not possible in general. For this, remember that in all solutions of $A'x=b'$, the components add up to a fixed number which must than also hold for $Ax=b$. But this property does not hold for general linear systems of equations. For example
$$
\left(\begin{matrix}
    1 & 0\\
    0 & 2
\end{matrix}\right)
x = \left(\begin{matrix}
    2\\2
\end{matrix}\right)
$$
yields among others the solutions $(2, 0)^\top$ and $(0, 1)^\top$, which clearly don't add up to the same number. 

We have to accept, that when creating the adapted system of equations, we also have to adapt the solutions. The hop is, that from the adapted solution we can recover the solutions we are looking for. This is indeed possible and is the basis for all further discussions.

\begin{theorem}
    Let $A\in \N^{m \times n}$ such that $A$ has no zero-column and $b \in \N^m$. Then, there exists $A' \in \N^{(m+1) \times (n+1)}$ and $b' \in \N^{m+1}$ such that all columns of $A$ sum up to the same number $\alpha \in \N^*$ and for every $x \in \N^n$:
    $$Ax = b \Leftrightarrow \exists x_{n+1}\in \N\colon A' \smat{
        x_1\\
        \vdots\\
        x_n\\
        x_{n+1}
    } = b'$$
\end{theorem}

\begin{proof}
    First we need to get an upper bound in the solutions $x \in \N^n$ in $Ax=b$. We will do that similarly as in the proof of Lemma \ref{lemma:ilp_pre1}. Let $s_j = \sum_{i=0}^{m} A_{ij}$, the column sum of the $j$-th column in $A$. Let $s := \min\{s_1, \dots, s_j\}$. Because $A$ has no zero-colmns $s > 0$.
    $$\sum_{i=1}^m b_i = \sum_{i=1}^{m}\sum_{j=1}^{n}A_{ij} x_j = \sum_{j=1}^{n}\underbrace{\sum_{i=1}^{m}A_{ij}}_{s_j} x_j \geq s \cdot \sum_{j=1}^{n}x_j \Leftrightarrow \sum_{j=1}^{n}x_j \leq \frac{1}{s}\sum_{i=1}^{m}b_i$$
    Now we can construct $A'$ and $b'$. Let $\alpha \geq \max\{s_1, \dots, s_n\}$ and $v_j := \alpha - s_j$. 
    $$A' :=
    \begin{pNiceArray}{cccc}[margin] 
    \Block[draw]{3-3}{A} & & & 0 \\
    & & & \vdots\\
    & & & 0\\
    v_1 & \dots  & v_n & \alpha 
    \end{pNiceArray} \in \N^{(m+1) \times (n+1)}
    \qquad b' := \mat{b_1\\\vdots\\b_m\\\beta} \in \N^{m+1}$$
    It is clear that in $A'$, all columns sum up to $\alpha$. Observe also that $s \leq \alpha$. Because of Lemma \ref{lemma:ilp_pre1} (2) we need to set $\beta := k \cdot \alpha - \sum_{i=0}^{m}b_i$ for some $k \in \N$. We will set $k \geq \frac{1}{s}\sum_{i=1}^{m}b_i$. Thus we get $\beta \geq \frac{\alpha}{s}\sum_{i=1}^{m}b_i - \sum_{i=1}^{m}b_i \geq 0$, because $\frac{\alpha}{s} \geq 1$, which is needed, as $\beta \in \N$. Now we have to prove the equivalince:
    \begin{itemize}
        \item[``$\Leftarrow$''] Because the first $m$ rows in $A'x=b'$ are equialent to $Ax=b$ discarding the last component of the solution $x_{n+1}$ we see that the vector $(x_1, \dots, x_n)^\top$ is indeed a solution to $Ax=b$.
        \item[``$\Rightarrow$''] Let $(x_1, \dots, x_n)$ be the solution of $Ax=b$. We we have to find a $x_{n+1} \in \N$ such that $x' := (x_1, \dots x_{n+1})$ is a solution to $A'x' = b'$. 
        
        Now we'll call $(x_1, \dots, x_{n+1}) =: x'$. Because of Lemma \ref{lemma:ilp_pre1} (1) we need to set $x_{n+1} := k - \sum_{j=1}^{n}x_j$. Similarly to the discussion on $\beta$, we also have to make sure for $x_{n+1}$, that it is $\geq 0$. $x_{n+1} \geq k - \frac{1}{s}\sum_{i=1}^{m}b_i \geq \frac{1}{s}\sum_{i=1}^{m}b_i - \frac{1}{s}\sum_{i=1}^{m}b_i = 0$.
        
        Now, we need to check whether $A'x'\stackrel{?}{=}b'$. Because the first $m$ rows in $A'x'=b'$ are equialent to $Ax=b$ discarding the last component of the solution $x_{n+1}$ we only have to check the last row. So we have to prove $(A'x')_{n+1} = \beta$
        \begin{align*}
            (A'x')_{n+1} &= \sum_{j=1}^{n}v_jx_j + \alpha \cdot x_{n+1} = \sum_{j=1}^{n}(\alpha - s_j)x_j + \alpha \cdot x_{n+1} = \alpha \cdot \sum_{j=1}^{n}x_j - \sum_{j=1}^{n}s_jx_j + \alpha \cdot x_{n+1}\\
            &= \alpha \cdot \underbrace{\left(\sum_{j=1}^{n}x_j + x_{n+1}\right)}_k - \sum_{j=1}^{n}s_jx_j = \alpha \cdot k - \sum_{j=1}^{n}\sum_{i=1}^{m}A_{ij}x_j = \alpha\cdot k - \sum_{i=1}^{m}\underbrace{\sum_{j=1}^{n}A_{ij}x_j}_{b_i}\\
            &= \alpha\cdot k - \sum_{i=1}^{m}b_i = \beta
        \end{align*}
    \end{itemize}
\end{proof}
So from this point on we can w.l.o.g. assume, that in any system of equations $Ax=b$ all columns sum up to the same number.

\section{Tropic polynomials}
Let $c_{e_1, \dots, e_m}(p)$ be the coefficiant in $p \in S[q_1, \dots q_m]$ of the monomial $p_1^{e_1}\dots p_m^{e_m}$. 

\begin{lemma}
    Let $A \in \N^{m \times n}$ and $w \in \R^n$. Let
    $$f := \bigoplus_{i=1}^{n} w^\top\hat e_i\odot  q_1^{(A\hat e_i)_1}\dots q_m^{(A\hat e_i)_m} \in \T[q_1, \dots, q_m]$$
    be a tropic polynomial. Then it will hold that
    $$c_{e_1, \dots, e_m}(f^{\odot l}) = \min\left\{w^\top v \mid v \in \N^n, \sum_{i=0}^{n}v_i = l, Av=\smat{e_1\\\vdots\\e_m}\right\}$$
\end{lemma}

\begin{theorem}
    Let $\min \stackrel{!}{=} w^\top x$ s.t. $Ax=b$ an ILP, such that all columns of $A$ sum up to the same number $\alpha \in \N^*$. We wat the ILP, to have solutions, so $k = \frac{1}{\alpha}\sum_{i=1}^{m}b_i \in \N$ exists. We will define the monomal $m_v := w^\top v \odot q_1^{(Av)_1}\dots q_n^{(Av)_n}$. Let $f \in S[q_1, \dots, q_n]$ be 
    $$f := \bigoplus_{i=1}^n m_{\hat e_i}$$
    Then $c_{b_1, \dots, b_n}(f^{\odot k})$ solves the ILP.
\end{theorem}