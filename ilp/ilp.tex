\chapter{Integer linear programs}
\section{Introduction}

\section{Preliminaries}
[Define a ILP?]

For us, it will be usefull to discuss matricies where all columns sum to the same number $\alpha$. Because we are in the framework of ILPs, we also use natural numbers as entries. So, we are interested in $A \in \N^{m \times n}$ if $\forall i \in [n]\colon \sum_{i=1}^{m}A_{ij} = \alpha$. These matricies have special properties when they are used in linear system of equations, which we will discover in the next lemma.

\begin{lemma}
    \label{lemma:ilp_pre1}
    Let $A\in \N^{m \times n}$ such that each column of $A$ sums up to the same number $\alpha \in \N$. Let $b \in \N^m$ arbitrary and consider the linear system of equation $Ax=b$, where $x \in \N^n$. Then, the following two statements are true

    \begin{enumerate}
        \item[(1)] For all solutions $x \in \R^n$ must hold that its components must always sum up to the same number $k$.
        \item[(2)] There only exist a solution of the components of $b$ sum up to a multiple of $\alpha$. This multiple turnes out to be $k \cdot \alpha$.
    \end{enumerate}
\end{lemma}

\begin{proof}
    Lets assume there exists a solution $x \in \R^n$ of the linear system of equation $Ax=b$.
    $$\sum_{i=1}^m b_i = \sum_{i=1}^{m}\sum_{j=1}^{n}A_{ij} x_j = \sum_{j=1}^{n}\underbrace{\sum_{i=1}^{m}A_{ij}}_\alpha x_j = \alpha \cdot \sum_{j=1}^{n}x_j$$
    Because $\alpha$ and $b_i$ are fixed and will not change dependent of $x$, statement (1) immidiatly follows. Thus we have proven, if there exist a solution $x \in \N^n$, then it must hold that $\sum_{i=1}^{m}b_i = \alpha \cdot k$ which is the contraposition of (2).
\end{proof}
Reviewing the last lemma, one might hope that we can convert any system of lineare equation $Ax = b$ in another $A'x = b'$ such that in $A'$ all columns sum up to the same number and $x$ is a solution to the first if and only if it is a solution to the second. It is easy to see, that this is sadly not possible in general. For this, remember that in all solutions of $A'x=b'$, the components add up to a fixed number which must than also hold for $Ax=b$. But this property does not hold for general linear systems of equations. For example
$$
\left(\begin{matrix}
    1 & 0\\
    0 & 2
\end{matrix}\right)
x = \left(\begin{matrix}
    2\\2
\end{matrix}\right)
$$
yields among others the solutions $(2, 0)^\top$ and $(0, 1)^\top$, which clearly don't add up to the same number. 

We have to accept, that when creating the adapted system of equations, we also have to adapt the solutions. The hop is, that from the adapted solution we can recover the solutions we are looking for. This is indeed possible and is the basis for all further discussions.

\begin{theorem}
    Let $A\in \N^{m \times n}$ and $b \in \N^m$. Then, there exists $A' \in \N^{(m+1) \times (n+1)}$ and $b' \in \N^{m+1}$ such that all columns of $A$ sum up to the same number $\alpha \in \N$ and for every $x \in \N^n$:
    $$Ax = b \Leftrightarrow \exists x_{n+1}\in \Z\colon A' \smat{
        x_1\\
        \vdots\\
        x_n\\
        x_{n+1}
    } = b'$$
\end{theorem}

\begin{proof}
    First we will construct $A'$ and $b'$:
    $$A' :=
    \begin{pNiceArray}{cccc}[margin] 
    \Block[draw]{3-3}{A} & & & 0 \\
    & & & \vdots\\
    & & & 0\\
    v_1 & \dots  & v_n & \alpha 
    \end{pNiceArray} \in \N^{(m+1) \times (n+1)}
    \qquad b' := \mat{b_1\\\vdots\\b_m\\\beta} \in \N^{m+1}$$
    with $v_j = \alpha - s_j$ and $s_j = \sum_{i=0}^{m} A_{ij}$. So $s_j$ is the sum of the $j$-th column in $A$. It is clear that in $A'$, all columns sum up to $\alpha$. Because of Lemma \ref{lemma:ilp_pre1} (2) we need to set $\beta := k \cdot \alpha - \sum_{i=0}^{m}b_i$ for some $k \in \N$. We have to chose high enough, so that $\beta \geq 0 \Leftrightarrow k \geq \frac{1}{\alpha}\sum_{i=1}^{m}b_i$, as $\beta \in \N$. Now we have to prove the equivalince:
    \begin{itemize}
        \item[``$\Leftarrow$''] Because the first $m$ rows in $A'x=b'$ are equialent to $Ax=b$ discarding the last component of the solution $x_{n+1}$ we see that the vector $(x_1, \dots, x_n)^\top$ is indeed a solution to $Ax=b$.
        \item[``$\Rightarrow$''] Let $(x_1, \dots, x_n)$ be the solution of $Ax=b$. We we have to find a $x_{n+1} \in \Z$ such that $x' := (x_1, \dots x_{n+1})$ is a solution to $A'x' = b'$. 
        
        
        Now we'll call $(x_1, \dots, x_{n+1}) =: x'$. Because of Lemma \ref{lemma:ilp_pre1} (1) we need to set $x_{n+1} := k - \sum_{i=1}^{n}$. As $x_{n+1} \in \Z$, this yields no further restrictions on $k$. We need to check whether $A'x'\stackrel{?}{=}b'$. Because the first $m$ rows in $A'x'=b'$ are equialent to $Ax=b$ discarding the last component of the solution $x_{n+1}$ we only have to check the last row. So we have to prove $(A'x')_{n+1} = \beta$
        \begin{align*}
            (A'x')_{n+1} &= \sum_{j=1}^{n}v_jx_j + \alpha \cdot x_{n+1} = \sum_{j=1}^{n}(\alpha - s_j)x_j + \alpha \cdot x_{n+1} = \alpha \cdot \sum_{j=1}^{n}x_j - \sum_{j=1}^{n}s_jx_j + \alpha \cdot x_{n+1}\\
            &= \alpha \cdot \underbrace{\left(\sum_{j=1}^{n}x_j + x_{n+1}\right)}_k - \sum_{j=1}^{n}s_jx_j = \alpha \cdot k - \sum_{j=1}^{n}\sum_{i=1}^{m}A_{ij}x_j = \alpha\cdot k - \sum_{i=1}^{m}\underbrace{\sum_{j=1}^{n}A_{ij}x_j}_{b_i}\\
            &= \alpha\cdot k - \sum_{i=1}^{m}b_i = \beta
        \end{align*}
    \end{itemize}
\end{proof}
So from this point on we can w.l.o.g. assume, that in any system of equations $Ax=b$ all columns sum up to the same number.